\chapter{Conclusions}\label{concl}
\thispagestyle{plain}

In this thesis three machine learning algorithms have been used to create models aimed at predicting glaciers ice thickness.

In order to do so, the GlaThiDa, a database with ice thickness observations of glaciers all over the world has been linked to the RGI, a database of glaciers outlines which include over 215,000 glaciers and represents all glaciers and ice caps in the globe. Of all the observations in GlaThiDa, 96.6\% have been associated with glaciers in the RGI, summing up to a total of only 771 glaciers worldwide with ice thickness observations. In many glaciers only few observations have been reported in the GlaThiDa, and some regions completely lack ice thickness measurements.

In order to create a data set to train the machine learning models, the Open Global Glacier Model has been used. This model provided the tools to merge together the relevant digital elevation models for each glacier, and compute gridded geometrical features such as: the topography, the distance from the border of the glacier, the slope angle and the altitude dependent linear mass balance.

With this data three different machine learning models, linear regression, random forest regression and support vector regression, have been trained using only observations available for the alpine region. To avoid over-fitting the models, and to be able to assess their performances, each model has been trained with 20 different sub-samples, each containing 75\% of data points available. The $R^2$ coefficient, also called score, calculated over the resulting 25\% of the data, has been chosen as a value to assess the performances of each model. The best performing model on average was the support vector regression with an average $R^2 = 0.55$. The spread of the score between the models trained with the different sub-samples has been found particularly high with much lower scores for some specific sub-samples. This is true for the three different machine learning algorithms used, as all of them showed drops in score for samples 5, 14 and 19. This behavior seems explainable by the fact that the sub-sample left out for training in these 3 cases was particularly hard to predict.
The model achieving the highest score when training them over the whole sample has been the random forest regression with a score of 0.57.

After the models have been trained the relevance of each feature in the models predictions has been analyzed. The mass balance was the most relevant feature for both the random forest and support vector regression, but for the linear regression it was the slope angle. Those two features however proved to be relevant for the predictions of all the models. Altitude and distance from the border seem to be much less important for the predictions of both the random forest and the linear regression model, while still being relevant for the support vector regression.

The trained machine learning models have been used to estimate the ice thickness of each of the glaciers in the Alps. The results have been compared to the one obtained by \citet{Farinotti2019}. All the machine learning models have been found to predict very different volumes compared to the ones predicted in the ITMIX. The linear regression is the only model which predicted a total ice volume larger than the one from ITMIX by over 9\%. The random forest and support vector machine predicted a total volume respectively 22\% and 25\% lower than ITMIX. These two models in fact seem to underestimate the ice thickness for large glaciers, leading to low volume values for those glaciers and hence for the whole region. Larger glaciers are essential in estimating the total volume of ice but are also outliers in the per-volume distribution of glaciers in the alps. The machine learning algorithms seem then unfit to make predictions about these larger glaciers. This could be explained by the fact that the models were not able to learn the patterns of these large glaciers, due to the fact that they had no information about them in the training data-set. 

After all, the machine learning algorithms have not been very accurate in estimating the ice thickness using the features chosen as input values. This applies particularly to large glaciers, for which the models seem unable to replicate accurate ice thicknesses.

A lot could be done to improve the machine learning models performances. 
One of the first thing to try could be the usage of different machine learning algorithms to train the model. An example could be the use of artificial neural networks as in the work of \citet{Clarke2009} which was however not based on real glacier data but on artificially grown ones. Artificial neural networks have in fact shown a lot of real life applications in the last years due to their accurate performances, and seeing how they would perform on the problem of estimating glacier ice thickness could be very interesting.
  
Using more and different features could also be a very interesting possibility. As mentioned adding the mass balance based on the catchment basins could already be a big improvement on the mass balance used. A smoothed version of this would be ideal but even the non-smoothed one could be beneficial. Even if the ice thickness distribution would look unrealistic it could still lead to better estimates for glacier volumes. Climate data like precipitation and temperature could also be used as they could be helpful in recognizing differences between glaciers.

Increasing the grid resolution could also improve the models performances. Many measurements have been in fact agglomerated into single ones due to the fact that they were all falling inside the same grid cell. Having more measurements could give the machine learning algorithms more room to learn. This could however also skew the predictions of the algorithms as glaciers with many more observations could have a much higher influence in the training process than those with few ones. 
 
Further research could also look into the data from other regions included in the GlaThiDa database.  This thing in particular could lead to glacier models able to predict glacier ice thickness for those regions better than the models trained in this thesis. In fact, if the observations for those regions were covering a wider spectrum of ice thickness values and feature values the models could be trained with data better representing the whole distribution of these values for the region than it happened in the case of the Alps. As machine learning models can only learn from the data fed to them those data are in fact extremely important.
 
The importance of collecting measurements for a wide spectrum of values is something to be taken into account for the future if the glaciology community wanted to really start using statistical methods to model glaciers. This problem could then be taken into consideration when choosing where to lead the campaigns to collect ice thickness measurements.
